#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ„å›¾è¯†åˆ«è°ƒè¯•è„šæœ¬
"""

import os
import sys
from pathlib import Path
from dotenv import load_dotenv

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

from llm.glm import get_glm_client
from llm.prompts import INTENT_RECOGNITION_PROMPT

def test_intent_recognition():
    """æµ‹è¯•æ„å›¾è¯†åˆ«"""
    print("ğŸ” å¼€å§‹æµ‹è¯•æ„å›¾è¯†åˆ«...")
    
    # åˆå§‹åŒ–GLMå®¢æˆ·ç«¯
    glm_client = get_glm_client()
    
    # æµ‹è¯•é—®é¢˜
    test_questions = [
        "ä½ å¥½",
        "ä½ æœ‰ä»€ä¹ˆæ•°æ®ï¼Ÿ",
        "æ•°æ®èŒƒå›´æœ‰å“ªäº›ï¼Ÿ"
    ]
    
    for question in test_questions:
        print(f"\nğŸ“ æµ‹è¯•é—®é¢˜: {question}")
        
        # ç”Ÿæˆæç¤ºè¯
        prompt = INTENT_RECOGNITION_PROMPT.format(user_question=question)
        print(f"\nğŸ“‹ æç¤ºè¯:\n{prompt}")
        
        # è°ƒç”¨GLMç”Ÿæˆå“åº”
        try:
            response = glm_client.generate_response(prompt)
            print(f"\nğŸ¤– GLMåŸå§‹å“åº”:\n{response}")
            
            # å°è¯•è§£æJSON
            result = glm_client.parse_json_response(prompt)
            print(f"\nâœ… JSONè§£æç»“æœ:\n{result}")
            
        except Exception as e:
            print(f"\nâŒ é”™è¯¯: {e}")
        
        print("\n" + "="*60)

if __name__ == "__main__":
    test_intent_recognition()