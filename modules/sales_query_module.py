#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é”€é‡æŸ¥è¯¢æ¨¡å— - åŸºäºä¹˜ç”¨è½¦ä¸Šé™©é‡æ•°æ®çš„å¤šç»´åº¦é”€é‡æŸ¥è¯¢

æ”¯æŒè‡ªç„¶è¯­è¨€æŸ¥è¯¢è½¬æ¢ä¸ºSQLæŸ¥è¯¢ï¼Œæä¾›çµæ´»çš„é”€é‡æ•°æ®åˆ†æèƒ½åŠ›ã€‚
"""

import pandas as pd
import json
from pathlib import Path
from typing import Dict, Any, List, Optional
from jinja2 import Template
import re
from datetime import datetime, timedelta
import logging
import os
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

from .base_module import BaseAnalysisModule
from llm.glm import GLMClient, get_glm_client
from llm.prompts import AI_INSIGHTS_GENERATION_PROMPT, SALES_QUERY_PARAMETER_EXTRACTION_PROMPT

logger = logging.getLogger(__name__)


class SalesQueryModule(BaseAnalysisModule):
    """é”€é‡æŸ¥è¯¢æ¨¡å—
    
    åŸºäºä¹˜ç”¨è½¦ä¸Šé™©é‡æ•°æ®çš„å¤šç»´åº¦é”€é‡æŸ¥è¯¢æ¨¡å—ï¼Œæ”¯æŒï¼š
    - å“ç‰Œé”€é‡æŸ¥è¯¢
    - æ—¶é—´è¶‹åŠ¿åˆ†æ
    - åœ°åŒºé”€é‡ç»Ÿè®¡
    - å¤šç»´åº¦ç»„åˆæŸ¥è¯¢
    - è‡ªç„¶è¯­è¨€å‚æ•°æå–
    """
    
    # æ¨¡å—åŸºæœ¬ä¿¡æ¯
    module_id = "sales_query"
    module_name = "é”€é‡æŸ¥è¯¢æ¨¡å—"
    description = "åŸºäºä¹˜ç”¨è½¦ä¸Šé™©é‡æ•°æ®çš„å¤šç»´åº¦é”€é‡æŸ¥è¯¢æ¨¡å—"
    
    # æ•°æ®åº“æ„ŸçŸ¥èƒ½åŠ›
    supported_databases = ["parquet", "duckdb", "pandas"]
    required_fields = ["sales_volume", "date"]
    optional_fields = [
        "brand", "model_name", "province", "city", 
        "fuel_type", "body_style", "is_luxury_brand", "city_tier"
    ]
    
    def __init__(self):
        """åˆå§‹åŒ–é”€é‡æŸ¥è¯¢æ¨¡å—"""
        super().__init__()
        self.query_templates = self._load_query_templates()
        self.brand_mapping = self._load_brand_mapping()
        self.region_mapping = self._load_region_mapping()
    
    def _load_query_templates(self) -> Dict[str, Any]:
        """åŠ è½½æŸ¥è¯¢æ¨¡æ¿"""
        return {
            "brand_sales": {
                "name": "å“ç‰Œé”€é‡æŸ¥è¯¢",
                "description": "æŸ¥è¯¢æŒ‡å®šå“ç‰Œçš„é”€é‡æ•°æ®",
                "template": """
                SELECT 
                    brand,
                    {% if model_names %}model_name,{% endif %}
                    SUM(sales_volume) as total_sales,
                    COUNT(*) as record_count,
                    AVG(sales_volume) as avg_sales
                FROM data 
                WHERE 1=1
                {% if brands %}
                    AND brand IN ({{ brands | map('tojsonfilter') | join(', ') }})
                {% endif %}
                {% if model_names %}
                    AND model_name IN ({{ model_names | map('tojsonfilter') | join(', ') }})
                {% endif %}
                {% if start_date %}
                    AND date >= '{{ start_date }}'
                {% endif %}
                {% if end_date %}
                    AND date <= '{{ end_date }}'
                {% endif %}
                GROUP BY brand{% if model_names %}, model_name{% endif %}
                ORDER BY total_sales DESC
                {% if limit %}
                    LIMIT {{ limit }}
                {% endif %}
                """,
                "required_params": [],
                "optional_params": ["brands", "model_names", "start_date", "end_date", "limit"],
                "result_columns": ["brand", "total_sales", "record_count", "avg_sales"]
            },
            "time_trend": {
                "name": "æ—¶é—´è¶‹åŠ¿æŸ¥è¯¢",
                "description": "æŸ¥è¯¢é”€é‡çš„æ—¶é—´è¶‹åŠ¿",
                "template": """
                SELECT 
                    date,
                    SUM(sales_volume) as total_sales,
                    COUNT(DISTINCT brand) as brand_count
                FROM data 
                WHERE 1=1
                {% if brands %}
                    AND brand IN ({{ brands | map('tojsonfilter') | join(', ') }})
                {% endif %}
                {% if start_date %}
                    AND date >= '{{ start_date }}'
                {% endif %}
                {% if end_date %}
                    AND date <= '{{ end_date }}'
                {% endif %}
                GROUP BY date
                ORDER BY date
                """,
                "required_params": [],
                "optional_params": ["brands", "start_date", "end_date"],
                "result_columns": ["date", "total_sales", "brand_count"]
            },
            "region_sales": {
                "name": "åœ°åŒºé”€é‡æŸ¥è¯¢",
                "description": "æŸ¥è¯¢æŒ‡å®šåœ°åŒºçš„é”€é‡æ•°æ®",
                "template": """
                SELECT 
                    province,
                    city,
                    {% if brands %}brand,{% endif %}
                    {% if model_names %}model_name,{% endif %}
                    SUM(sales_volume) as total_sales,
                    COUNT(DISTINCT brand) as brand_count
                FROM data 
                WHERE 1=1
                {% if provinces %}
                    AND province IN ({{ provinces | map('tojsonfilter') | join(', ') }})
                {% endif %}
                {% if cities %}
                    AND city IN ({{ cities | map('tojsonfilter') | join(', ') }})
                {% endif %}
                {% if brands %}
                    AND brand IN ({{ brands | map('tojsonfilter') | join(', ') }})
                {% endif %}
                {% if model_names %}
                    AND model_name IN ({{ model_names | map('tojsonfilter') | join(', ') }})
                {% endif %}
                GROUP BY province, city{% if brands %}, brand{% endif %}{% if model_names %}, model_name{% endif %}
                ORDER BY total_sales DESC
                {% if limit %}
                    LIMIT {{ limit }}
                {% endif %}
                """,
                "required_params": [],
                "optional_params": ["provinces", "cities", "brands", "model_names", "limit"],
                "result_columns": ["province", "city", "total_sales", "brand_count"]
            },
            "fuel_type_analysis": {
                "name": "ç‡ƒæ–™ç±»å‹åˆ†æ",
                "description": "æŒ‰ç‡ƒæ–™ç±»å‹åˆ†æé”€é‡",
                "template": """
                SELECT 
                    fuel_type,
                    {% if brands %}brand,{% endif %}
                    {% if model_names %}model_name,{% endif %}
                    SUM(sales_volume) as total_sales,
                    COUNT(DISTINCT brand) as brand_count,
                    AVG(sales_volume) as avg_sales
                FROM data 
                WHERE 1=1
                {% if fuel_types %}
                    AND fuel_type IN ({{ fuel_types | map('tojsonfilter') | join(', ') }})
                {% endif %}
                {% if brands %}
                    AND brand IN ({{ brands | map('tojsonfilter') | join(', ') }})
                {% endif %}
                {% if model_names %}
                    AND model_name IN ({{ model_names | map('tojsonfilter') | join(', ') }})
                {% endif %}
                GROUP BY fuel_type{% if brands %}, brand{% endif %}{% if model_names %}, model_name{% endif %}
                ORDER BY total_sales DESC
                """,
                "required_params": [],
                "optional_params": ["fuel_types", "brands", "model_names"],
                "result_columns": ["fuel_type", "total_sales", "brand_count", "avg_sales"]
            },
            "model_sales": {
                "name": "è½¦å‹é”€é‡æŸ¥è¯¢",
                "description": "æŸ¥è¯¢æŒ‡å®šè½¦å‹çš„é”€é‡æ•°æ®",
                "template": """
                SELECT 
                    brand,
                    model_name,
                    SUM(sales_volume) as total_sales,
                    COUNT(*) as record_count,
                    AVG(sales_volume) as avg_sales
                FROM data 
                WHERE 1=1
                {% if brands %}
                    AND brand IN ({{ brands | map('tojsonfilter') | join(', ') }})
                {% endif %}
                {% if model_names %}
                    AND model_name IN ({{ model_names | map('tojsonfilter') | join(', ') }})
                {% endif %}
                {% if start_date %}
                    AND date >= '{{ start_date }}'
                {% endif %}
                {% if end_date %}
                    AND date <= '{{ end_date }}'
                {% endif %}
                GROUP BY brand, model_name
                ORDER BY total_sales DESC
                {% if limit %}
                    LIMIT {{ limit }}
                {% endif %}
                """,
                "required_params": [],
                "optional_params": ["brands", "model_names", "start_date", "end_date", "limit"],
                "result_columns": ["brand", "model_name", "total_sales", "record_count", "avg_sales"]
            },
            "general_sales": {
                "name": "ç»¼åˆé”€é‡æŸ¥è¯¢",
                "description": "é€šç”¨é”€é‡æŸ¥è¯¢æ¨¡æ¿",
                "template": """
                SELECT 
                    brand,
                    SUM(sales_volume) as total_sales
                FROM data 
                GROUP BY brand
                ORDER BY total_sales DESC
                LIMIT 10
                """,
                "required_params": [],
                "optional_params": [],
                "result_columns": ["brand", "total_sales"]
            }
        }
    
    def _load_brand_mapping(self) -> Dict[str, str]:
        """åŠ è½½å“ç‰Œæ˜ å°„è¡¨"""
        return {
            "ç‰¹æ–¯æ‹‰": "Tesla",
            "æ¯”äºšè¿ª": "BYD",
            "è”šæ¥": "NIO",
            "å°é¹": "XPENG",
            "ç†æƒ³": "Li Auto",
            "æ™ºå·±": "IM Motors",
            "æ™ºç•Œ": "AITO",
            "ææ°ª": "Zeekr",
            "æç‹": "ARCFOX",
            "å²šå›¾": "Voyah",
            "é˜¿ç»´å¡”": "AVATR",
            "æ·±è“": "Deepal",
            "é—®ç•Œ": "AITO",
            "å¥”é©°": "Mercedes-Benz",
            "å®é©¬": "BMW",
            "å¥¥è¿ª": "Audi",
            "å¤§ä¼—": "Volkswagen",
            "ä¸°ç”°": "Toyota",
            "æœ¬ç”°": "Honda",
            "æ—¥äº§": "Nissan",
            "ç°ä»£": "Hyundai",
            "èµ·äºš": "KIA",
            "æ²ƒå°”æ²ƒ": "Volvo",
            "æ·è±¹": "Jaguar",
            "è·¯è™": "Land Rover",
            "ä¿æ—¶æ·": "Porsche",
            "æ³•æ‹‰åˆ©": "Ferrari",
            "ç›èæ‹‰è’‚": "Maserati",
            "å®¾åˆ©": "Bentley",
            "åŠ³æ–¯è±æ–¯": "Rolls-Royce"
        }
    
    def _load_region_mapping(self) -> Dict[str, str]:
        """åŠ è½½åœ°åŒºæ˜ å°„è¡¨"""
        return {
            "åŒ—äº¬": "åŒ—äº¬å¸‚",
            "ä¸Šæµ·": "ä¸Šæµ·å¸‚",
            "å¹¿å·": "å¹¿ä¸œçœ",
            "æ·±åœ³": "å¹¿ä¸œçœ",
            "æ­å·": "æµ™æ±Ÿçœ",
            "å—äº¬": "æ±Ÿè‹çœ",
            "æˆéƒ½": "å››å·çœ",
            "é‡åº†": "é‡åº†å¸‚",
            "è¥¿å®‰": "é™•è¥¿çœ",
            "æ­¦æ±‰": "æ¹–åŒ—çœ"
        }
    
    def prepare_data(self, db_connector: Any, params: Dict[str, Any]) -> pd.DataFrame:
        """å‡†å¤‡æ•°æ®
        
        Args:
            db_connector: æ•°æ®åº“è¿æ¥å™¨ï¼ˆæš‚æ—¶ä¸ä½¿ç”¨ï¼‰
            params: å‚æ•°å­—å…¸
            
        Returns:
            pandas.DataFrame: åŠ è½½çš„æ•°æ®
        """
        try:
            # è·å–æ•°æ®æºè·¯å¾„
            data_source = params.get('data_source', 'data/ä¹˜ç”¨è½¦ä¸Šé™©é‡_0723.parquet')
            
            # å¦‚æœæ˜¯ç›¸å¯¹è·¯å¾„ï¼Œè½¬æ¢ä¸ºç»å¯¹è·¯å¾„
            if not Path(data_source).is_absolute():
                project_root = Path(__file__).parent.parent
                data_source = project_root / data_source
            
            logger.info(f"åŠ è½½æ•°æ®æº: {data_source}")
            
            # åŠ è½½parquetæ–‡ä»¶
            if Path(data_source).exists():
                df = pd.read_parquet(data_source)
                logger.info(f"æ•°æ®åŠ è½½æˆåŠŸï¼Œå½¢çŠ¶: {df.shape}")
                return df
            else:
                raise FileNotFoundError(f"æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_source}")
                
        except Exception as e:
            logger.error(f"æ•°æ®å‡†å¤‡å¤±è´¥: {e}")
            raise
    
    def run(self, data: pd.DataFrame, params: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡ŒæŸ¥è¯¢
        
        Args:
            data: å‡†å¤‡å¥½çš„æ•°æ®
            params: æŸ¥è¯¢å‚æ•°
            
        Returns:
            Dict[str, Any]: æŸ¥è¯¢ç»“æœ
        """
        try:
            # 1. æå–æŸ¥è¯¢å‚æ•°
            extracted_params = self._extract_query_parameters(params)
            
            # 2. é€‰æ‹©æŸ¥è¯¢æ¨¡æ¿
            template_info = self._select_template(extracted_params)
            
            # 3. æ„å»ºå¹¶æ‰§è¡ŒæŸ¥è¯¢
            result_df = self._execute_query(data, template_info, extracted_params)
            
            # 4. æ ¼å¼åŒ–ç»“æœ
            result = self._format_results(result_df, template_info, extracted_params)
            result['success'] = True
            return result
            
        except Exception as e:
            logger.error(f"æŸ¥è¯¢æ‰§è¡Œå¤±è´¥: {e}")
            return {
                "success": False,
                "data": [],
                "analysis": {"error": str(e)},
                "visualization": {},
                "insights": [f"æŸ¥è¯¢æ‰§è¡Œå¤±è´¥: {str(e)}"]
            }
    
    def summarize(self, results: Dict[str, Any]) -> str:
        """ç”ŸæˆæŸ¥è¯¢ç»“æœæ‘˜è¦
        
        Args:
            results: æŸ¥è¯¢ç»“æœ
            
        Returns:
            str: æ–‡å­—æ‘˜è¦
        """
        try:
            data = results.get('data', [])
            analysis = results.get('analysis', {})
            insights = results.get('insights', [])
            
            if not data:
                return "æŸ¥è¯¢æœªè¿”å›ä»»ä½•ç»“æœã€‚"
            
            # æ„å»ºç»“æ„åŒ–çš„è¿”å›ç»“æœ
            summary_parts = []
            
            # 1. æŸ¥è¯¢ç»“æœæ¦‚è¿°
            data_summary = analysis.get('data_summary', {})
            if data_summary.get('sales_stats'):
                stats = data_summary['sales_stats']
                summary_parts.append(f"ğŸ“Š æŸ¥è¯¢ç»“æœï¼šå…±æ‰¾åˆ° {len(data)} æ¡è®°å½•")
                summary_parts.append(f"ğŸ’° æ€»é”€é‡ï¼š{stats['total']:,.0f} è¾†")
                if len(data) > 1:
                    summary_parts.append(f"ğŸ“ˆ å¹³å‡é”€é‡ï¼š{stats['average']:,.0f} è¾†")
                    summary_parts.append(f"ğŸ” æœ€é«˜é”€é‡ï¼š{stats['max']:,.0f} è¾†")
            else:
                summary_parts.append(f"ğŸ“Š æŸ¥è¯¢ç»“æœï¼šå…±æ‰¾åˆ° {len(data)} æ¡è®°å½•")
            
            # 2. å…·ä½“æ•°æ®å±•ç¤ºï¼ˆå‰3æ¡ï¼‰
            if data:
                summary_parts.append("\nğŸ” è¯¦ç»†æ•°æ®ï¼š")
                for i, item in enumerate(data[:3]):
                    if 'brand' in item and 'total_sales' in item:
                        if 'model_name' in item:
                            summary_parts.append(f"  {i+1}. {item['brand']} {item['model_name']}ï¼š{item['total_sales']:,.0f} è¾†")
                        else:
                            summary_parts.append(f"  {i+1}. {item['brand']}ï¼š{item['total_sales']:,.0f} è¾†")
                    elif 'province' in item and 'total_sales' in item:
                        city_info = f" {item['city']}" if item.get('city') else ""
                        summary_parts.append(f"  {i+1}. {item['province']}{city_info}ï¼š{item['total_sales']:,.0f} è¾†")
                    elif 'fuel_type' in item and 'total_sales' in item:
                        summary_parts.append(f"  {i+1}. {item['fuel_type']}ï¼š{item['total_sales']:,.0f} è¾†")
                    else:
                        # é€šç”¨æ ¼å¼
                        sales_value = item.get('total_sales', item.get('sales', 0))
                        summary_parts.append(f"  {i+1}. é”€é‡ï¼š{sales_value:,.0f} è¾†")
                
                if len(data) > 3:
                    summary_parts.append(f"  ... è¿˜æœ‰ {len(data) - 3} æ¡è®°å½•")
            
            # 3. æ´å¯Ÿåˆ†æ
            if insights:
                summary_parts.append("\nğŸ’¡ æ•°æ®æ´å¯Ÿï¼š")
                for insight in insights[:2]:  # åªæ˜¾ç¤ºå‰2ä¸ªæ´å¯Ÿ
                    if insight and len(insight.strip()) > 0:
                        summary_parts.append(f"  â€¢ {insight.strip()}")
            
            return "\n".join(summary_parts)
                
        except Exception as e:
            logger.error(f"æ‘˜è¦ç”Ÿæˆå¤±è´¥: {e}")
            return f"æŸ¥è¯¢å®Œæˆï¼Œä½†æ‘˜è¦ç”Ÿæˆå¤±è´¥: {str(e)}"
    
    def _extract_query_parameters(self, params: Dict[str, Any]) -> Dict[str, Any]:
        """ä»ç”¨æˆ·é—®é¢˜ä¸­æå–æŸ¥è¯¢å‚æ•°ï¼ˆä½¿ç”¨GLMæ™ºèƒ½æå–ï¼‰"""
        user_question = params.get('user_question', '')
        
        try:
            # ä½¿ç”¨GLMè¿›è¡Œæ™ºèƒ½å‚æ•°æå–
            glm_client = get_glm_client()
            prompt = SALES_QUERY_PARAMETER_EXTRACTION_PROMPT.format(user_question=user_question)
            extracted_params = glm_client.parse_json_response(prompt)
            
            # å¦‚æœGLMæå–å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨çš„æ­£åˆ™è¡¨è¾¾å¼æ–¹æ³•
            if "error" in extracted_params:
                logger.warning(f"GLMå‚æ•°æå–å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ³•: {extracted_params}")
                return self._extract_query_parameters_fallback(user_question)
            
            # æ ‡å‡†åŒ–æå–çš„å‚æ•°
            extracted = {
                'user_question': user_question,
                'brands': extracted_params.get('brands', []),
                'model_names': extracted_params.get('model_names', []),
                'provinces': extracted_params.get('provinces', []),
                'cities': extracted_params.get('cities', []),
                'fuel_types': extracted_params.get('fuel_types', []),
                'start_date': extracted_params.get('start_date'),
                'end_date': extracted_params.get('end_date'),
                'limit': extracted_params.get('limit'),
                'time_granularity': extracted_params.get('time_granularity', 'year')
            }
            
            # æ¸…ç†è½¦å‹åç§°ä¸­çš„å“ç‰Œå‰ç¼€
            extracted = self._clean_model_names(extracted)
            
            logger.info(f"GLMå‚æ•°æå–æˆåŠŸ: {extracted}")
            return extracted
            
        except Exception as e:
            logger.error(f"GLMå‚æ•°æå–å¼‚å¸¸: {e}ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ³•")
            return self._extract_query_parameters_fallback(params)
    
    def _extract_query_parameters_fallback(self, params) -> Dict[str, Any]:
        """å¤‡ç”¨çš„æ­£åˆ™è¡¨è¾¾å¼å‚æ•°æå–æ–¹æ³•"""
        # å¤„ç†å‚æ•°ç±»å‹
        if isinstance(params, str):
            user_question = params
        elif isinstance(params, dict):
            user_question = params.get('user_question', '')
        else:
            user_question = str(params)
        extracted = {
            'user_question': user_question,
            'brands': [],
            'model_names': [],
            'provinces': [],
            'cities': [],
            'fuel_types': [],
            'start_date': None,
            'end_date': None,
            'limit': None,
            'time_granularity': 'year'
        }
        
        # æå–å“ç‰Œä¿¡æ¯
        for chinese_name, english_name in self.brand_mapping.items():
            if chinese_name in user_question or english_name.lower() in user_question.lower():
                extracted['brands'].append(chinese_name)
        
        # æå–è½¦å‹ä¿¡æ¯ï¼ˆæ”¹è¿›çš„æ­£åˆ™è¡¨è¾¾å¼ï¼‰
        model_patterns = [
            r'æ™ºå·±LS[67]|æ™ºå·±L[67]', # æ™ºå·±LS6, æ™ºå·±L7, æ™ºå·±L6
            r'ç‰¹æ–¯æ‹‰Model\s*[XYZ3S]', # ç‰¹æ–¯æ‹‰Model Y, ç‰¹æ–¯æ‹‰Model 3
            r'Model\s*[XYZ3S]', # Model Y, Model 3
            r'å®é©¬[X\dç³»]+', # å®é©¬X5, å®é©¬3ç³»
            r'å¥”é©°[A-Z\dçº§]+', # å¥”é©°Cçº§, å¥”é©°Eçº§
            r'æ¯”äºšè¿ª[æ±‰å”å®‹å…ƒç§¦æµ·è±šæµ·è±¹é©±é€èˆ°æŠ¤å«èˆ°]+',  # æ¯”äºšè¿ªæ±‰ã€æ¯”äºšè¿ªå”ç­‰
            r'è”šæ¥ES[68]|è”šæ¥ET[57]',    # è”šæ¥ES6ã€ES8, è”šæ¥ET5ã€ET7ç­‰
            r'ç†æƒ³ONE|ç†æƒ³L[789]',      # ç†æƒ³ONE, ç†æƒ³L7, ç†æƒ³L8, ç†æƒ³L9
            r'å°é¹P[57]|å°é¹G[39]',     # å°é¹P5ã€P7, å°é¹G3ã€G9ç­‰
        
        ]
        
        # å¤„ç†å¤šä¸ªè½¦å‹çš„æƒ…å†µ
        # 1. å…ˆç”¨åŸæ–¹æ³•åœ¨æ•´ä¸ªé—®é¢˜ä¸­æŸ¥æ‰¾
        for pattern in model_patterns:
            matches = re.findall(pattern, user_question)
            for match in matches:
                if match not in extracted['model_names']:
                    extracted['model_names'].append(match)
        
        # 2. å†å¤„ç†ç”¨åˆ†éš”ç¬¦è¿æ¥çš„è½¦å‹
        # åˆ†å‰²ç”¨æˆ·é—®é¢˜ï¼Œæå–æ‰€æœ‰å¯èƒ½çš„è½¦å‹
        question_parts = re.split(r'[å’Œã€ï¼Œ,ä¸åŠ]', user_question)
        
        for part in question_parts:
            part = part.strip()
            for pattern in model_patterns:
                matches = re.findall(pattern, part)
                for match in matches:
                    if match not in extracted['model_names']:
                        extracted['model_names'].append(match)
        
        # 3. ç‰¹æ®Šå¤„ç†ï¼šæ‰‹åŠ¨è¯†åˆ«ä¸€äº›å¸¸è§çš„è½¦å‹ç»„åˆ
        special_patterns = [
            r'Model\s*([A-Z0-9]+)',  # Model Y, Model 3ç­‰
            r'ES(\d+)',             # ES6, ES8ç­‰
            r'ET(\d+)',             # ET7, ET5ç­‰
        ]
        
        for pattern in special_patterns:
            matches = re.findall(pattern, user_question)
            for match in matches:
                if 'Model' in pattern:
                    full_name = f"ç‰¹æ–¯æ‹‰Model {match}"
                elif 'ES' in pattern:
                    full_name = f"è”šæ¥ES{match}"
                elif 'ET' in pattern:
                    full_name = f"è”šæ¥ET{match}"
                
                if full_name not in extracted['model_names']:
                    extracted['model_names'].append(full_name)
        
        # æå–åœ°åŒºä¿¡æ¯
        for region_name, province_name in self.region_mapping.items():
            if region_name in user_question:
                if province_name.endswith('å¸‚'):
                    extracted['cities'].append(region_name + 'å¸‚')
                else:
                    extracted['provinces'].append(province_name)
        
        # æå–ç‡ƒæ–™ç±»å‹
        fuel_keywords = {
            'ç”µåŠ¨': ['çº¯ç”µåŠ¨'],
            'æ··åŠ¨': ['æ’ç”µå¼æ··åˆåŠ¨åŠ›'],
            'æ±½æ²¹': ['æ±½æ²¹'],
            'æ–°èƒ½æº': ['çº¯ç”µåŠ¨', 'æ’ç”µå¼æ··åˆåŠ¨åŠ›']
        }
        
        for keyword, fuel_types in fuel_keywords.items():
            if keyword in user_question:
                extracted['fuel_types'].extend(fuel_types)
        
        # æå–æ—¶é—´èŒƒå›´ï¼ˆæ”¹è¿›çš„æ—¶é—´è¯†åˆ«ï¼‰
        current_year = datetime.now().year
        current_month = datetime.now().month
        
        # æœˆä»½è¯†åˆ«ï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼‰
        month_patterns = [
            r'(\d{4})å¹´(\d{1,2})æœˆ',  # 2024å¹´3æœˆ
            r'(\d{1,2})æœˆ',           # 3æœˆï¼ˆå½“å¹´ï¼‰
        ]
        
        month_found = False
        for pattern in month_patterns:
            matches = re.findall(pattern, user_question)
            for match in matches:
                if isinstance(match, tuple) and len(match) == 2:  # å¹´æœˆéƒ½æœ‰
                    year_int, month_int = int(match[0]), int(match[1])
                else:  # åªæœ‰æœˆä»½
                    year_int, month_int = current_year, int(match)
                
                if 1 <= month_int <= 12:
                    # è®¡ç®—æœˆä»½çš„æœ€åä¸€å¤©
                    if month_int == 12:
                        next_month = 1
                        next_year = year_int + 1
                    else:
                        next_month = month_int + 1
                        next_year = year_int
                    
                    last_day = (datetime(next_year, next_month, 1) - timedelta(days=1)).day
                    
                    extracted['start_date'] = f"{year_int}-{month_int:02d}-01"
                    extracted['end_date'] = f"{year_int}-{month_int:02d}-{last_day}"
                    extracted['time_granularity'] = 'month'
                    month_found = True
                    break
            if month_found:
                break
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æœˆä»½ï¼Œå†è¯†åˆ«å¹´ä»½
        if not month_found:
            year_patterns = [
                r'(\d{4})å¹´',  # 2024å¹´
                r'(\d{4})',    # 2024
            ]
            
            for pattern in year_patterns:
                years = re.findall(pattern, user_question)
                for year in years:
                    year_int = int(year)
                    if 2020 <= year_int <= current_year + 1:  # åˆç†çš„å¹´ä»½èŒƒå›´
                        extracted['start_date'] = f"{year_int}-01-01"
                        extracted['end_date'] = f"{year_int}-12-31"
                        extracted['time_granularity'] = 'year'
                        break
        
        # å­£åº¦è¯†åˆ«ï¼ˆå¦‚æœæ²¡æœ‰æ‰¾åˆ°æœˆä»½ï¼‰
        if not month_found:
            quarter_patterns = [
                r'(\d{4})å¹´ç¬¬([ä¸€äºŒä¸‰å››1234])å­£åº¦',
                r'ç¬¬([ä¸€äºŒä¸‰å››1234])å­£åº¦',
            ]
            
            quarter_map = {'ä¸€': 1, 'äºŒ': 2, 'ä¸‰': 3, 'å››': 4, '1': 1, '2': 2, '3': 3, '4': 4}
            
            quarter_found = False
            for pattern in quarter_patterns:
                matches = re.findall(pattern, user_question)
                for match in matches:
                    if isinstance(match, tuple) and len(match) == 2:  # å¹´ä»½å’Œå­£åº¦éƒ½æœ‰
                        year_int = int(match[0])
                        quarter = quarter_map.get(match[1])
                    else:  # åªæœ‰å­£åº¦
                        year_int = current_year
                        quarter = quarter_map.get(match)
                    
                    if quarter:
                        start_month = (quarter - 1) * 3 + 1
                        end_month = quarter * 3
                        
                        # è®¡ç®—å­£åº¦æœ€åä¸€å¤©
                        if end_month == 12:
                            last_day = 31
                        else:
                            last_day = (datetime(year_int, end_month + 1, 1) - timedelta(days=1)).day
                        
                        extracted['start_date'] = f"{year_int}-{start_month:02d}-01"
                        extracted['end_date'] = f"{year_int}-{end_month:02d}-{last_day}"
                        extracted['time_granularity'] = 'month'
                        quarter_found = True
                        break
                if quarter_found:
                    break
            
            # å¦‚æœæ‰¾åˆ°äº†å­£åº¦ï¼Œæ›´æ–°month_foundæ ‡å¿—
            if quarter_found:
                month_found = True
        
        # åŠå¹´è¯†åˆ«
        if 'ä¸ŠåŠå¹´' in user_question:
            year_match = re.search(r'(\d{4})å¹´?ä¸ŠåŠå¹´', user_question)
            year_int = int(year_match.group(1)) if year_match else current_year
            extracted['start_date'] = f"{year_int}-01-01"
            extracted['end_date'] = f"{year_int}-06-30"
            extracted['time_granularity'] = 'month'
        elif 'ä¸‹åŠå¹´' in user_question:
            year_match = re.search(r'(\d{4})å¹´?ä¸‹åŠå¹´', user_question)
            year_int = int(year_match.group(1)) if year_match else current_year
            extracted['start_date'] = f"{year_int}-07-01"
            extracted['end_date'] = f"{year_int}-12-31"
            extracted['time_granularity'] = 'month'
        
        # ç›¸å¯¹æ—¶é—´è¯†åˆ«
        if 'ä»Šå¹´' in user_question:
            extracted['start_date'] = f"{current_year}-01-01"
            extracted['end_date'] = f"{current_year}-12-31"
            extracted['time_granularity'] = 'year'
        elif 'å»å¹´' in user_question:
            last_year = current_year - 1
            extracted['start_date'] = f"{last_year}-01-01"
            extracted['end_date'] = f"{last_year}-12-31"
            extracted['time_granularity'] = 'year'
        elif 'æœ€è¿‘ä¸€å¹´' in user_question or 'è¿‘ä¸€å¹´' in user_question:
            one_year_ago = datetime.now() - timedelta(days=365)
            extracted['start_date'] = one_year_ago.strftime('%Y-%m-%d')
            extracted['end_date'] = datetime.now().strftime('%Y-%m-%d')
            extracted['time_granularity'] = 'year'
        
        # æ—¶é—´èŒƒå›´è¯†åˆ«ï¼ˆå¦‚2023-2024å¹´ï¼‰
        range_pattern = r'(\d{4})[-åˆ°è‡³](\d{4})å¹´?'
        range_match = re.search(range_pattern, user_question)
        if range_match:
            start_year = int(range_match.group(1))
            end_year = int(range_match.group(2))
            extracted['start_date'] = f"{start_year}-01-01"
            extracted['end_date'] = f"{end_year}-12-31"
            extracted['time_granularity'] = 'year'
        
        # æå–æ•°é‡é™åˆ¶
        limit_patterns = [r'å‰(\d+)å', r'top\s*(\d+)', r'å‰(\d+)', r'(\d+)å¼º']
        for pattern in limit_patterns:
            match = re.search(pattern, user_question, re.IGNORECASE)
            if match:
                extracted['limit'] = int(match.group(1))
                break
        
        # å»é‡
        extracted['brands'] = list(set(extracted['brands']))
        extracted['model_names'] = list(set(extracted['model_names']))
        extracted['provinces'] = list(set(extracted['provinces']))
        extracted['cities'] = list(set(extracted['cities']))
        extracted['fuel_types'] = list(set(extracted['fuel_types']))
        
        return extracted
    
    def _clean_model_names(self, extracted: Dict[str, Any]) -> Dict[str, Any]:
        """æ™ºèƒ½å¤„ç†è½¦å‹åç§°ï¼Œç¡®ä¿ä¸æ•°æ®åº“ä¸­çš„å®é™…åç§°åŒ¹é…"""
        if not extracted.get('model_names'):
            return extracted
        
        brands = extracted.get('brands', [])
        processed_models = []
        
        # å®šä¹‰éœ€è¦ä¿ç•™å®Œæ•´åç§°çš„å“ç‰Œï¼ˆè¿™äº›å“ç‰Œçš„è½¦å‹åœ¨æ•°æ®åº“ä¸­åŒ…å«å“ç‰Œå‰ç¼€ï¼‰
        keep_full_name_brands = ['æ™ºå·±', 'è”šæ¥', 'ç†æƒ³', 'å°é¹']
        
        # å®šä¹‰ç‰¹æ–¯æ‹‰è½¦å‹çš„ç‰¹æ®Šå¤„ç†ï¼ˆæ•°æ®åº“ä¸­æ˜¯å¤§å†™çš„MODELï¼‰
        tesla_model_mapping = {
            'Model Y': 'MODEL Y',
            'Model 3': 'MODEL 3', 
            'Model S': 'MODEL S',
            'Model X': 'MODEL X',
            'model y': 'MODEL Y',
            'model 3': 'MODEL 3',
            'model s': 'MODEL S', 
            'model x': 'MODEL X'
        }
        
        for model in extracted['model_names']:
            if not model:
                continue
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯éœ€è¦ä¿ç•™å®Œæ•´åç§°çš„å“ç‰Œ
            should_keep_full = False
            for keep_brand in keep_full_name_brands:
                if model.startswith(keep_brand):
                    should_keep_full = True
                    break
            
            # ç‰¹æ–¯æ‹‰è½¦å‹çš„ç‰¹æ®Šå¤„ç†
            if model in tesla_model_mapping:
                processed_models.append(tesla_model_mapping[model])
            elif model.startswith('ç‰¹æ–¯æ‹‰') and any(tesla_name in model for tesla_name in tesla_model_mapping.keys()):
                # å¤„ç†"ç‰¹æ–¯æ‹‰Model Y"è¿™æ ·çš„æ ¼å¼
                for original, mapped in tesla_model_mapping.items():
                    if original in model:
                        processed_models.append(mapped)
                        break
                else:
                    processed_models.append(model)
            elif should_keep_full:
                # å¯¹äºæ™ºå·±ç­‰å“ç‰Œï¼Œä¿ç•™å®Œæ•´çš„è½¦å‹åç§°
                processed_models.append(model)
            else:
                # å¯¹äºå…¶ä»–å“ç‰Œï¼Œå°è¯•å»é™¤å“ç‰Œå‰ç¼€
                cleaned_model = model
                for brand in brands:
                    if brand and model.startswith(brand) and brand not in keep_full_name_brands:
                        # å»é™¤å“ç‰Œåç§°å’Œå¯èƒ½çš„ç©ºæ ¼
                        cleaned_model = model[len(brand):].strip()
                        break
                
                # å¦‚æœæ¸…ç†åçš„è½¦å‹åç§°ä¸ä¸ºç©ºï¼Œåˆ™ä½¿ç”¨æ¸…ç†åçš„åç§°ï¼Œå¦åˆ™ä½¿ç”¨åŸåç§°
                if cleaned_model:
                    processed_models.append(cleaned_model)
                else:
                    processed_models.append(model)
        
        extracted['model_names'] = processed_models
        return extracted
    
    def _select_template(self, params: Dict[str, Any]) -> Dict[str, Any]:
        """é€‰æ‹©åˆé€‚çš„æŸ¥è¯¢æ¨¡æ¿"""
        user_question = params.get('user_question', '').lower()
        
        # è¿‡æ»¤Noneå€¼çš„è¾…åŠ©å‡½æ•°
        def has_valid_values(param_list):
            return param_list and any(item is not None for item in param_list)
        
        # åˆ†æç”¨æˆ·é—®é¢˜çš„å…³é”®è¯æ¥åˆ¤æ–­æ„å›¾
        brand_keywords = ['å“ç‰Œé”€é‡', 'å“ç‰Œ', 'ç‰Œå­']
        model_keywords = ['è½¦å‹é”€é‡', 'è½¦å‹', 'å‹å·', 'model']
        trend_keywords = ['è¶‹åŠ¿', 'å˜åŒ–', 'æœˆåº¦', 'å­£åº¦', 'èµ°åŠ¿', 'å‘å±•']
        region_keywords = ['åœ°åŒº', 'çœä»½', 'åŸå¸‚', 'åŒºåŸŸ']
        fuel_keywords = ['ç‡ƒæ–™', 'ç”µåŠ¨', 'æ··åŠ¨', 'æ±½æ²¹', 'æ–°èƒ½æº']
        
        # æ ¹æ®é—®é¢˜å†…å®¹å’Œå‚æ•°é€‰æ‹©æ¨¡æ¿
        # ä¼˜å…ˆè€ƒè™‘æ˜ç¡®çš„å…³é”®è¯æ„å›¾
        if any(keyword in user_question for keyword in brand_keywords) and has_valid_values(params.get('brands')):
            # æ˜ç¡®çš„å“ç‰ŒæŸ¥è¯¢æ„å›¾
            if any(keyword in user_question for keyword in trend_keywords):
                return self.query_templates['time_trend']
            else:
                return self.query_templates['brand_sales']
        elif any(keyword in user_question for keyword in model_keywords) and has_valid_values(params.get('model_names')):
            # æ˜ç¡®çš„è½¦å‹æŸ¥è¯¢æ„å›¾
            return self.query_templates['model_sales']
        elif any(keyword in user_question for keyword in fuel_keywords) and has_valid_values(params.get('fuel_types')):
            return self.query_templates['fuel_type_analysis']
        elif any(keyword in user_question for keyword in region_keywords) and (has_valid_values(params.get('provinces')) or has_valid_values(params.get('cities'))):
            return self.query_templates['region_sales']
        elif any(keyword in user_question for keyword in trend_keywords) and (params.get('start_date') or params.get('end_date')):
            return self.query_templates['time_trend']
        # å¦‚æœæ²¡æœ‰æ˜ç¡®å…³é”®è¯ï¼ŒæŒ‰å‚æ•°ä¼˜å…ˆçº§é€‰æ‹©
        elif has_valid_values(params.get('model_names')):
            return self.query_templates['model_sales']
        elif has_valid_values(params.get('fuel_types')):
            return self.query_templates['fuel_type_analysis']
        elif has_valid_values(params.get('provinces')) or has_valid_values(params.get('cities')):
            return self.query_templates['region_sales']
        elif has_valid_values(params.get('brands')):
            # å¦‚æœé—®é¢˜åŒ…å«"è¶‹åŠ¿"ã€"å˜åŒ–"ã€"æœˆåº¦"ç­‰å…³é”®è¯ï¼Œä½¿ç”¨æ—¶é—´è¶‹åŠ¿æ¨¡æ¿
            if any(keyword in user_question for keyword in trend_keywords):
                return self.query_templates['time_trend']
            # å¦åˆ™ä½¿ç”¨å“ç‰Œé”€é‡æ¨¡æ¿
            else:
                return self.query_templates['brand_sales']
        elif params.get('start_date') or params.get('end_date'):
            return self.query_templates['time_trend']
        else:
            return self.query_templates['general_sales']
    
    def _execute_query(self, data: pd.DataFrame, template_info: Dict[str, Any], params: Dict[str, Any]) -> pd.DataFrame:
        """æ‰§è¡ŒæŸ¥è¯¢ï¼ˆä½¿ç”¨pandasæ¨¡æ‹ŸSQLï¼‰"""
        try:
            # å¤åˆ¶æ•°æ®ä»¥é¿å…ä¿®æ”¹åŸå§‹æ•°æ®
            df = data.copy()
            
            # åº”ç”¨è¿‡æ»¤æ¡ä»¶ï¼ˆè¿‡æ»¤Noneå€¼ï¼‰
            if params.get('brands'):
                valid_brands = [b for b in params['brands'] if b is not None]
                if valid_brands:
                    df = df[df['brand'].isin(valid_brands)]
                    # é‡ç½®brandåˆ—çš„åˆ†ç±»ï¼Œé¿å…groupbyæ—¶åŒ…å«æœªä½¿ç”¨çš„åˆ†ç±»
                    if hasattr(df['brand'], 'cat'):
                        df['brand'] = df['brand'].cat.remove_unused_categories()
            
            if params.get('provinces'):
                valid_provinces = [p for p in params['provinces'] if p is not None]
                if valid_provinces:
                    df = df[df['province'].isin(valid_provinces)]
            
            if params.get('cities'):
                valid_cities = [c for c in params['cities'] if c is not None]
                if valid_cities:
                    df = df[df['city'].isin(valid_cities)]
            
            if params.get('fuel_types'):
                valid_fuel_types = [f for f in params['fuel_types'] if f is not None]
                if valid_fuel_types:
                    df = df[df['fuel_type'].isin(valid_fuel_types)]
            
            # æ—¶é—´è¿‡æ»¤ï¼ˆè½¬æ¢å­—ç¬¦ä¸²æ—¥æœŸä¸ºdatetimeå¯¹è±¡ï¼‰
            if params.get('start_date'):
                start_date = pd.to_datetime(params['start_date'])
                df = df[df['date'] >= start_date]
            
            if params.get('end_date'):
                end_date = pd.to_datetime(params['end_date'])
                df = df[df['date'] <= end_date]
            
            # è½¦å‹è¿‡æ»¤
            if params.get('model_names'):
                valid_model_names = [m for m in params['model_names'] if m is not None]
                if valid_model_names:
                    df = df[df['model_name'].isin(valid_model_names)]
            
            # æ ¹æ®æ¨¡æ¿ç±»å‹æ‰§è¡Œèšåˆ
            template_name = template_info['name']
            
            if 'è½¦å‹é”€é‡' in template_name:
                if df.empty:
                    result = pd.DataFrame(columns=['brand', 'model_name', 'total_sales', 'record_count', 'avg_sales'])
                else:
                    result = df.groupby(['brand', 'model_name']).agg({
                        'sales_volume': ['sum', 'count', 'mean']
                    }).round(2)
                    # ä¿®å¤å¤šçº§ç´¢å¼•åˆ—åé—®é¢˜
                    result.columns = result.columns.droplevel(0)  # ç§»é™¤ç¬¬ä¸€çº§ç´¢å¼•
                    result.columns = ['total_sales', 'record_count', 'avg_sales']
                    result = result.reset_index().sort_values('total_sales', ascending=False)
                    # è¿‡æ»¤æ‰0é”€é‡çš„è®°å½•
                    result = result[result['total_sales'] > 0]
                    
            elif 'å“ç‰Œé”€é‡' in template_name:
                if df.empty:
                    base_columns = ['brand', 'total_sales', 'record_count', 'avg_sales']
                    if params.get('model_names'):
                        base_columns.insert(1, 'model_name')
                    result = pd.DataFrame(columns=base_columns)
                else:
                    # æ ¹æ®æ˜¯å¦æœ‰è½¦å‹å‚æ•°å†³å®šåˆ†ç»„æ–¹å¼
                    group_cols = ['brand']
                    if params.get('model_names'):
                        group_cols.append('model_name')
                    
                    result = df.groupby(group_cols).agg({
                        'sales_volume': ['sum', 'count', 'mean']
                    }).round(2)
                    # ä¿®å¤å¤šçº§ç´¢å¼•åˆ—åé—®é¢˜
                    result.columns = result.columns.droplevel(0)  # ç§»é™¤ç¬¬ä¸€çº§ç´¢å¼•
                    result.columns = ['total_sales', 'record_count', 'avg_sales']
                    result = result.reset_index().sort_values('total_sales', ascending=False)
                    # è¿‡æ»¤æ‰0é”€é‡çš„è®°å½•
                    result = result[result['total_sales'] > 0]
                
            elif 'æ—¶é—´è¶‹åŠ¿' in template_name:
                result = df.groupby('date').agg({
                    'sales_volume': 'sum',
                    'brand': 'nunique'
                }).round(2)
                result.columns = ['total_sales', 'brand_count']
                result = result.reset_index().sort_values('date')
                
            elif 'åœ°åŒºé”€é‡' in template_name:
                # æ ¹æ®å‚æ•°å†³å®šåˆ†ç»„åˆ—
                group_cols = ['province', 'city']
                if params.get('brands'):
                    group_cols.append('brand')
                if params.get('model_names'):
                    group_cols.append('model_name')
                    
                result = df.groupby(group_cols).agg({
                    'sales_volume': 'sum',
                    'brand': 'nunique'
                }).round(2)
                # ä¿®å¤å¤šçº§ç´¢å¼•åˆ—åé—®é¢˜
                result.columns = result.columns.droplevel(0)  # ç§»é™¤ç¬¬ä¸€çº§ç´¢å¼•
                result.columns = ['total_sales', 'brand_count']
                result = result.reset_index().sort_values('total_sales', ascending=False)
                # è¿‡æ»¤æ‰0é”€é‡çš„è®°å½•
                result = result[result['total_sales'] > 0]
                
            elif 'ç‡ƒæ–™ç±»å‹' in template_name:
                # æ ¹æ®å‚æ•°å†³å®šåˆ†ç»„åˆ—
                group_cols = ['fuel_type']
                if params.get('brands'):
                    group_cols.append('brand')
                if params.get('model_names'):
                    group_cols.append('model_name')
                    
                result = df.groupby(group_cols).agg({
                    'sales_volume': ['sum', 'count', 'mean'],
                    'brand': 'nunique'
                }).round(2)
                # ä¿®å¤å¤šçº§ç´¢å¼•åˆ—åé—®é¢˜
                result.columns = result.columns.droplevel(0)  # ç§»é™¤ç¬¬ä¸€çº§ç´¢å¼•
                result.columns = ['total_sales', 'record_count', 'avg_sales', 'brand_count']
                result = result.reset_index().sort_values('total_sales', ascending=False)
                # è¿‡æ»¤æ‰0é”€é‡çš„è®°å½•
                result = result[result['total_sales'] > 0]
                
            else:  # ç»¼åˆé”€é‡æŸ¥è¯¢
                result = df.groupby('brand')['sales_volume'].sum().reset_index()
                result.columns = ['brand', 'total_sales']
                result = result.sort_values('total_sales', ascending=False)
                # è¿‡æ»¤æ‰0é”€é‡çš„è®°å½•
                result = result[result['total_sales'] > 0].head(10)
            
            # åº”ç”¨é™åˆ¶
            if params.get('limit'):
                result = result.head(params['limit'])
            
            return result
            
        except Exception as e:
            logger.error(f"æŸ¥è¯¢æ‰§è¡Œå¤±è´¥: {e}")
            return pd.DataFrame()
    
    def _format_results(self, result_df: pd.DataFrame, template_info: Dict[str, Any], params: Dict[str, Any]) -> Dict[str, Any]:
        """æ ¼å¼åŒ–æŸ¥è¯¢ç»“æœ"""
        try:
            # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
            data = result_df.to_dict('records') if not result_df.empty else []
            
            # ç”Ÿæˆåˆ†æç»Ÿè®¡
            analysis = {
                'query_type': template_info['name'].replace('æŸ¥è¯¢', '').replace('åˆ†æ', ''),
                'template_used': template_info['name'],
                'total_records': len(data),
                'parameters_used': {k: v for k, v in params.items() if v},
                'data_summary': self._generate_data_summary(result_df)
            }
            
            # ç”Ÿæˆå¯è§†åŒ–é…ç½®
            visualization = self._generate_visualization_config(result_df, template_info)
            
            # ç”Ÿæˆæ´å¯Ÿ
            insights = self._generate_insights(result_df, template_info, params)
            
            return {
                'data': data,
                'analysis': analysis,
                'visualization': visualization,
                'insights': insights
            }
            
        except Exception as e:
            logger.error(f"ç»“æœæ ¼å¼åŒ–å¤±è´¥: {e}")
            return {
                'data': [],
                'analysis': {'error': str(e)},
                'visualization': {},
                'insights': [f"ç»“æœæ ¼å¼åŒ–å¤±è´¥: {str(e)}"]
            }
    
    def _generate_data_summary(self, df: pd.DataFrame) -> Dict[str, Any]:
        """ç”Ÿæˆæ•°æ®æ‘˜è¦"""
        if df.empty:
            return {'message': 'æ— æ•°æ®'}
        
        summary = {
            'record_count': len(df),
            'columns': list(df.columns)
        }
        
        # å¦‚æœæœ‰é”€é‡åˆ—ï¼Œè®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        sales_columns = [col for col in df.columns if 'sales' in col.lower()]
        if sales_columns:
            sales_col = sales_columns[0]
            summary['sales_stats'] = {
                'total': float(df[sales_col].sum()),
                'average': float(df[sales_col].mean()),
                'max': float(df[sales_col].max()),
                'min': float(df[sales_col].min())
            }
        
        return summary
    
    def _generate_visualization_config(self, df: pd.DataFrame, template_info: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆå¯è§†åŒ–é…ç½®"""
        if df.empty:
            return {}
        
        config = {
            'chart_type': 'bar',
            'title': template_info['name'],
            'data_ready': True
        }
        
        # æ ¹æ®æ•°æ®ç±»å‹é€‰æ‹©å›¾è¡¨ç±»å‹
        if 'date' in df.columns:
            config['chart_type'] = 'line'
            config['x_axis'] = 'date'
        elif 'brand' in df.columns:
            config['chart_type'] = 'bar'
            config['x_axis'] = 'brand'
        
        # è®¾ç½®yè½´
        sales_columns = [col for col in df.columns if 'sales' in col.lower()]
        if sales_columns:
            config['y_axis'] = sales_columns[0]
        
        return config
    
    def _generate_insights(self, df: pd.DataFrame, template_info: Dict[str, Any], params: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆæ•°æ®æ´å¯Ÿ - ä½¿ç”¨AIç”Ÿæˆæ·±åº¦æ´å¯Ÿ"""
        if df.empty:
            return ["æŸ¥è¯¢æ¡ä»¶ä¸‹æ²¡æœ‰æ‰¾åˆ°ç›¸å…³æ•°æ®"]
        
        try:
            # å°è¯•ä½¿ç”¨AIç”Ÿæˆæ·±åº¦æ´å¯Ÿ
            ai_insights = self._generate_ai_insights(df, template_info, params)
            if ai_insights:
                return ai_insights
        except Exception as e:
            logger.warning(f"AIæ´å¯Ÿç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨åŸºç¡€æ´å¯Ÿ: {e}")
        
        # å¤‡é€‰æ–¹æ¡ˆï¼šä½¿ç”¨åŸºç¡€æ´å¯Ÿ
        return self._generate_basic_insights(df, template_info, params)
    
    def _generate_ai_insights(self, df: pd.DataFrame, template_info: Dict[str, Any], params: Dict[str, Any]) -> List[str]:
        """ä½¿ç”¨AIç”Ÿæˆç®€åŒ–æ´å¯Ÿ"""
        try:
            # åˆå§‹åŒ–GLMå®¢æˆ·ç«¯
            glm_client = GLMClient()
            
            # å‡†å¤‡ç®€åŒ–æ•°æ®æ‘˜è¦
            query_data = self._prepare_simple_data_summary(df)
            brands = self._extract_brands(df)
            
            # è°ƒç”¨AIç”Ÿæˆæ´å¯Ÿ
            prompt = AI_INSIGHTS_GENERATION_PROMPT.format(
                query_data=query_data,
                query_params=self._format_query_params(params),
                user_question=params.get('user_question', 'é”€é‡æ•°æ®æŸ¥è¯¢')
            )
            
            response = glm_client.generate_response(prompt)
            
            # ç®€å•æ–‡æœ¬è§£æ
            insights = self._parse_simple_insights(response)
            
            return insights
            
        except Exception as e:
            logger.error(f"AIæ´å¯Ÿç”Ÿæˆå¤±è´¥: {e}")
            raise
    
    def _generate_basic_insights(self, df: pd.DataFrame, template_info: Dict[str, Any], params: Dict[str, Any]) -> List[str]:
        """ç”ŸæˆåŸºç¡€æ•°æ®æ´å¯Ÿï¼ˆå¤‡é€‰æ–¹æ¡ˆï¼‰"""
        insights = []
        
        # åŸºæœ¬ç»Ÿè®¡æ´å¯Ÿ
        insights.append(f"æŸ¥è¯¢è¿”å›äº† {len(df)} æ¡è®°å½•")
        
        # é”€é‡ç›¸å…³æ´å¯Ÿ
        sales_columns = [col for col in df.columns if 'sales' in col.lower()]
        if sales_columns:
            sales_col = sales_columns[0]
            total_sales = df[sales_col].sum()
            insights.append(f"æ€»é”€é‡ä¸º {total_sales:,.0f} è¾†")
            
            if len(df) > 1:
                top_item = df.iloc[0]
                if 'brand' in df.columns:
                    insights.append(f"é”€é‡æœ€é«˜çš„å“ç‰Œæ˜¯ {top_item['brand']}ï¼Œé”€é‡ä¸º {top_item[sales_col]:,.0f} è¾†")
                elif 'province' in df.columns:
                    insights.append(f"é”€é‡æœ€é«˜çš„åœ°åŒºæ˜¯ {top_item['province']}ï¼Œé”€é‡ä¸º {top_item[sales_col]:,.0f} è¾†")
        
        return insights
    
    def _prepare_simple_data_summary(self, df: pd.DataFrame) -> str:
        """ä¸ºAIå‡†å¤‡ç®€åŒ–æ•°æ®æ‘˜è¦"""
        try:
            summary = []
            
            # æ£€æŸ¥æ˜¯å¦æœ‰é”€é‡ç›¸å…³åˆ—
            sales_col = None
            if 'total_sales' in df.columns:
                sales_col = 'total_sales'
            elif 'sales_volume' in df.columns:
                sales_col = 'sales_volume'
            
            if sales_col:
                # å“ç‰Œé”€é‡å‰3ï¼ˆå¦‚æœæœ‰brandåˆ—ï¼‰
                if 'brand' in df.columns:
                    if sales_col == 'total_sales':
                        # å·²ç»èšåˆçš„æ•°æ®
                        top_brands = df.nlargest(3, sales_col)
                        summary.append(f"é”€é‡å‰3å“ç‰Œï¼š{', '.join([f'{row["brand"]}({row[sales_col]:,.0f}è¾†)' for _, row in top_brands.iterrows()])}")
                    else:
                        # åŸå§‹æ•°æ®ï¼Œéœ€è¦èšåˆ
                        brand_sales = df.groupby('brand')[sales_col].sum().sort_values(ascending=False)
                        top_brands = brand_sales.head(3)
                        summary.append(f"é”€é‡å‰3å“ç‰Œï¼š{', '.join([f'{b}({v:,.0f}è¾†)' for b, v in top_brands.items()])}")
                
                # æ€»é”€é‡
                total_sales = df[sales_col].sum()
                summary.append(f"æ€»é”€é‡ï¼š{total_sales:,.0f}è¾†")
            else:
                summary.append(f"å…±{len(df)}æ¡è®°å½•")
            
            return "; ".join(summary) if summary else f"å…±{len(df)}æ¡è®°å½•"
            
        except Exception as e:
            logger.error(f"å‡†å¤‡ç®€åŒ–æ•°æ®æ‘˜è¦å¤±è´¥: {e}")
            return f"å…±{len(df)}æ¡è®°å½•"
    
    def _extract_brands(self, df: pd.DataFrame) -> str:
        """æå–æ¶‰åŠçš„å“ç‰Œä¿¡æ¯"""
        if 'brand' in df.columns:
            brands = df['brand'].unique().tolist()
            return ', '.join(brands[:5])  # æœ€å¤šæ˜¾ç¤º5ä¸ªå“ç‰Œ
        return 'æœªæŒ‡å®šå“ç‰Œ'
    
    def _format_query_params(self, params: Dict[str, Any]) -> str:
        """æ ¼å¼åŒ–æŸ¥è¯¢å‚æ•°ä¸ºå¯è¯»å­—ç¬¦ä¸²"""
        try:
            param_parts = []
            
            # æ·»åŠ å“ç‰Œä¿¡æ¯
            if params.get('brands'):
                # è¿‡æ»¤Noneå€¼
                brands = [b for b in params['brands'] if b is not None]
                if brands:
                    param_parts.append(f"å“ç‰Œ: {', '.join(brands)}")
            
            # æ·»åŠ è½¦å‹ä¿¡æ¯
            if params.get('model_names'):
                # è¿‡æ»¤Noneå€¼
                models = [m for m in params['model_names'] if m is not None]
                if models:
                    param_parts.append(f"è½¦å‹: {', '.join(models)}")
            
            # æ·»åŠ åœ°åŒºä¿¡æ¯
            if params.get('provinces'):
                # è¿‡æ»¤Noneå€¼
                provinces = [p for p in params['provinces'] if p is not None]
                if provinces:
                    param_parts.append(f"çœä»½: {', '.join(provinces)}")
            if params.get('cities'):
                # è¿‡æ»¤Noneå€¼
                cities = [c for c in params['cities'] if c is not None]
                if cities:
                    param_parts.append(f"åŸå¸‚: {', '.join(cities)}")
            
            # æ·»åŠ æ—¶é—´èŒƒå›´
            if params.get('start_date') or params.get('end_date'):
                start_date = params.get('start_date') or ''
                end_date = params.get('end_date') or ''
                time_range = f"{start_date} è‡³ {end_date}"
                param_parts.append(f"æ—¶é—´èŒƒå›´: {time_range.strip()}")
            
            # æ·»åŠ ç‡ƒæ–™ç±»å‹
            if params.get('fuel_types'):
                # è¿‡æ»¤Noneå€¼
                fuel_types = [f for f in params['fuel_types'] if f is not None]
                if fuel_types:
                    param_parts.append(f"ç‡ƒæ–™ç±»å‹: {', '.join(fuel_types)}")
            
            # æ·»åŠ é™åˆ¶æ¡ä»¶
            if params.get('limit') and params.get('limit') is not None:
                param_parts.append(f"é™åˆ¶æ¡æ•°: {params['limit']}")
            
            return '; '.join(param_parts) if param_parts else 'æ— ç‰¹å®šç­›é€‰æ¡ä»¶'
            
        except Exception as e:
            logger.error(f"æ ¼å¼åŒ–æŸ¥è¯¢å‚æ•°å¤±è´¥: {e}")
            return 'å‚æ•°æ ¼å¼åŒ–å¤±è´¥'
    
    def _parse_simple_insights(self, response: str) -> List[str]:
        """ç®€å•è§£æAIå“åº”ä¸ºæ´å¯Ÿåˆ—è¡¨"""
        try:
            # æŒ‰è¡Œåˆ†å‰²å¹¶æ¸…ç†
            lines = [line.strip() for line in response.split('\n') if line.strip()]
            
            # è¿‡æ»¤æ‰å¤ªçŸ­çš„è¡Œ
            insights = [line for line in lines if len(line) > 10]
            
            # å¦‚æœæ²¡æœ‰æœ‰æ•ˆæ´å¯Ÿï¼Œè¿”å›åŸå§‹å“åº”çš„å‰200å­—ç¬¦
            if not insights:
                insights = [response[:200] + '...' if len(response) > 200 else response]
            
            return insights[:5]  # æœ€å¤šè¿”å›5ä¸ªæ´å¯Ÿ
            
        except Exception as e:
            logger.error(f"æ´å¯Ÿè§£æå¤±è´¥: {e}")
            return ["AIåˆ†æå®Œæˆï¼Œè¯·æŸ¥çœ‹å…·ä½“æ•°æ®ç»“æœ"]
    

    
    def _generate_brand_sales_summary(self, data: List[Dict], analysis: Dict[str, Any]) -> str:
        """ç”Ÿæˆå“ç‰Œé”€é‡æ‘˜è¦"""
        if not data:
            return "æœªæ‰¾åˆ°ç›¸å…³å“ç‰Œçš„é”€é‡æ•°æ®ã€‚"
        
        total_sales = sum(item.get('total_sales', 0) for item in data)
        top_brand = data[0]
        
        summary = f"æŸ¥è¯¢åˆ° {len(data)} ä¸ªå“ç‰Œçš„é”€é‡æ•°æ®ï¼Œæ€»é”€é‡ä¸º {total_sales:,.0f} è¾†ã€‚"
        summary += f"é”€é‡æœ€é«˜çš„å“ç‰Œæ˜¯ {top_brand['brand']}ï¼Œé”€é‡ä¸º {top_brand['total_sales']:,.0f} è¾†ã€‚"
        
        return summary
    
    def _generate_time_trend_summary(self, data: List[Dict], analysis: Dict[str, Any]) -> str:
        """ç”Ÿæˆæ—¶é—´è¶‹åŠ¿æ‘˜è¦"""
        if not data:
            return "æœªæ‰¾åˆ°ç›¸å…³æ—¶é—´æ®µçš„é”€é‡æ•°æ®ã€‚"
        
        total_sales = sum(item.get('total_sales', 0) for item in data)
        date_range = f"{data[0]['date']} åˆ° {data[-1]['date']}"
        
        summary = f"æ—¶é—´æ®µ {date_range} å†…ï¼Œæ€»é”€é‡ä¸º {total_sales:,.0f} è¾†ï¼Œ"
        summary += f"æ¶µç›– {len(data)} ä¸ªæ—¶é—´ç‚¹ã€‚"
        
        return summary
    
    def _generate_region_sales_summary(self, data: List[Dict], analysis: Dict[str, Any]) -> str:
        """ç”Ÿæˆåœ°åŒºé”€é‡æ‘˜è¦"""
        if not data:
            return "æœªæ‰¾åˆ°ç›¸å…³åœ°åŒºçš„é”€é‡æ•°æ®ã€‚"
        
        total_sales = sum(item.get('total_sales', 0) for item in data)
        top_region = data[0]
        
        summary = f"æŸ¥è¯¢åˆ° {len(data)} ä¸ªåœ°åŒºçš„é”€é‡æ•°æ®ï¼Œæ€»é”€é‡ä¸º {total_sales:,.0f} è¾†ã€‚"
        summary += f"é”€é‡æœ€é«˜çš„åœ°åŒºæ˜¯ {top_region['province']} {top_region['city']}ï¼Œé”€é‡ä¸º {top_region['total_sales']:,.0f} è¾†ã€‚"
        
        return summary
    
    def _generate_fuel_type_summary(self, data: List[Dict], analysis: Dict[str, Any]) -> str:
        """ç”Ÿæˆç‡ƒæ–™ç±»å‹æ‘˜è¦"""
        if not data:
            return "æœªæ‰¾åˆ°ç›¸å…³ç‡ƒæ–™ç±»å‹çš„é”€é‡æ•°æ®ã€‚"
        
        total_sales = sum(item.get('total_sales', 0) for item in data)
        top_fuel = data[0]
        
        summary = f"æŸ¥è¯¢åˆ° {len(data)} ç§ç‡ƒæ–™ç±»å‹çš„é”€é‡æ•°æ®ï¼Œæ€»é”€é‡ä¸º {total_sales:,.0f} è¾†ã€‚"
        summary += f"é”€é‡æœ€é«˜çš„ç‡ƒæ–™ç±»å‹æ˜¯ {top_fuel['fuel_type']}ï¼Œé”€é‡ä¸º {top_fuel['total_sales']:,.0f} è¾†ã€‚"
        
        return summary
    
    def _generate_general_summary(self, data: List[Dict], analysis: Dict[str, Any]) -> str:
        """ç”Ÿæˆé€šç”¨æ‘˜è¦"""
        if not data:
            return "æŸ¥è¯¢æœªè¿”å›ä»»ä½•æ•°æ®ã€‚"
        
        return f"æŸ¥è¯¢å®Œæˆï¼Œè¿”å› {len(data)} æ¡è®°å½•ã€‚"


# ä¸ºäº†æ”¯æŒJinja2æ¨¡æ¿ä¸­çš„tojsonfilter
def tojsonfilter(value):
    """å°†å€¼è½¬æ¢ä¸ºJSONæ ¼å¼çš„å­—ç¬¦ä¸²"""
    import json
    return json.dumps(value)


# æ³¨å†Œè‡ªå®šä¹‰è¿‡æ»¤å™¨
from jinja2 import Environment
env = Environment()
env.filters['tojsonfilter'] = tojsonfilter